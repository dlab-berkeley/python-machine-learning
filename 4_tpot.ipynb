{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "4_tpot.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHrn44ZxtFgM"
      },
      "source": [
        "# Part 4: TPOT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz5xBfzwtFgO"
      },
      "source": [
        "Without an extensive background in the statistics and mathematics behind different machine learning models, it can be difficult to determine what the best model for a given dataset is. This also applies to tuning the parameters. As you have probably noticed, the models we've used in this workshop so far have many different parameters, and it's by no means obvious how to tune them. \n",
        "\n",
        "Moreover, testing out many different models, along with many different combinations of parameters, could be extremely time consuming and impractical. \n",
        "\n",
        "[TPOT](https://github.com/rhiever/tpot) is a new tool that automates the model selection and hyperparameter tuning process using genetic programming. It also determines what preprocessing, if any, is necessary, such as PCA or standard scaling. It then exports this model to a file with the scikit-learn code written for you. \n",
        "\n",
        "Although it is in your best interest to learn as much about the theory behind machine learning as possible, tools like TPOT can theoretically do the work for you. \n",
        "\n",
        "TPOT can be used for both classification and regression.\n",
        "\n",
        "Let's set the random seed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIzs_JkntFgP"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kZEF9dvtFgQ"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7FmeeLPtFgQ"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR2x_IWStFgQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
        "                                                    train_size=0.75, test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Aq8EiCWtFgR",
        "outputId": "c209e723-f5f0-4f0e-d941-242f29011633"
      },
      "source": [
        "!pip install tpot\n",
        "from tpot import TPOTClassifier\n",
        "\n",
        "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=1)\n",
        "tpot.fit(X_train, y_train)\n",
        "print(tpot.score(X_test, y_test))\n",
        "tpot.export('tpot_cancer_pipeline.py')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tpot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/55/a7185198f554ea19758e5ac4641f100c94cba4585e738e2e48e3c40a0b7f/TPOT-0.11.7-py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.2MB/s \n",
            "\u001b[?25hCollecting deap>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/d1/803c7a387d8a7e6866160b1541307f88d534da4291572fb32f69d2548afb/deap-1.3.1-cp37-cp37m-manylinux2010_x86_64.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 17.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from tpot) (4.41.1)\n",
            "Collecting stopit>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
            "Collecting xgboost>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/35/169eec194bf1f9ef52ed670f5032ef2abaf6ed285cfadcb4b6026b800fc9/xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7MB)\n",
            "\u001b[K     |████████████████████████████████| 166.7MB 28kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tpot) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.0.1)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.19.5)\n",
            "Collecting update-checker>=0.16\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->tpot) (2018.9)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update-checker>=0.16->tpot) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-cp37-none-any.whl size=11954 sha256=239941e359327494b06cd0d5b12246f97579302f4d69ea929db790d4bb5ec718\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
            "Successfully built stopit\n",
            "Installing collected packages: deap, stopit, xgboost, update-checker, tpot\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed deap-1.3.1 stopit-1.1.2 tpot-0.11.7 update-checker-0.18.0 xgboost-1.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best pipeline: ExtraTreesClassifier(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), bootstrap=False, criterion=gini, max_features=0.35000000000000003, min_samples_leaf=3, min_samples_split=8, n_estimators=100)\n",
            "0.986013986013986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxvnuxKQtFgR"
      },
      "source": [
        "Let's look at the model TPOT created for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihMhIrZytFgS",
        "outputId": "059efc0b-60e1-4751-d467-f8166581dcc2"
      },
      "source": [
        "!cat tpot_cancer_pipeline.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "from sklearn.ensemble import ExtraTreesClassifier\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.pipeline import make_pipeline\n",
            "from sklearn.preprocessing import PolynomialFeatures\n",
            "\n",
            "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
            "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
            "features = tpot_data.drop('target', axis=1)\n",
            "training_features, testing_features, training_target, testing_target = \\\n",
            "            train_test_split(features, tpot_data['target'], random_state=None)\n",
            "\n",
            "# Average CV score on the training set was: 0.9670861833105336\n",
            "exported_pipeline = make_pipeline(\n",
            "    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n",
            "    ExtraTreesClassifier(bootstrap=False, criterion=\"gini\", max_features=0.35000000000000003, min_samples_leaf=3, min_samples_split=8, n_estimators=100)\n",
            ")\n",
            "\n",
            "exported_pipeline.fit(training_features, training_target)\n",
            "results = exported_pipeline.predict(testing_features)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5W8FJzYtFgS"
      },
      "source": [
        "## Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U2Y1jm1tFgS"
      },
      "source": [
        "First we'll load the preprocessed heart data that we created during the regression tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-V6O1mnuEKO"
      },
      "source": [
        "heart_data = np.load('data/heart_preproc.npz')\n",
        "\n",
        "X_train = heart_data['X_train']\n",
        "X_test = heart_data['X_test']\n",
        "y_train = heart_data['y_train']\n",
        "y_test = heart_data['y_test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEUH8AQ7tFgT"
      },
      "source": [
        "Now TPOT will make the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLk9vm97tFgT"
      },
      "source": [
        "from tpot import TPOTRegressor\n",
        "\n",
        "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=1, scoring='r2')  # generations for optimization, pop size is models\n",
        "tpot.fit(X_train, y_train.ravel())\n",
        "print(tpot.score(X_test, y_test.ravel()))\n",
        "tpot.export('tpot_heart_pipeline.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISZBpsL_tFgU"
      },
      "source": [
        "!cat tpot_heart_pipeline.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPE9JOFttFgU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}